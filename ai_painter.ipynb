{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Drawing App with AI Painting Conversion\n",
    "\n",
    "This notebook demonstrates how to create a simple drawing application using PyQt5 and convert the drawing into a famous painting using a pre-trained model from Hugging Face. The application will allow users to draw stick figures and see them transformed into paintings.\n"
   ],
   "id": "3e6b0880018d634d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 1: Import Libraries\n",
    "\n",
    "We need to import the necessary libraries for our application.\n"
   ],
   "id": "abfd9d1b92c71451"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T08:37:31.790132Z",
     "start_time": "2024-07-25T08:37:31.573936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from PyQt5.QtWidgets import QApplication, QMainWindow, QVBoxLayout, QPushButton, QLabel, QWidget\n",
    "from PyQt5.QtGui import QPainter, QPen, QPixmap, QImage\n",
    "from PyQt5.QtCore import Qt, QPoint\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import torch\n",
    "from diffusers import StableDiffusionImg2ImgPipeline\n",
    "import sys\n"
   ],
   "id": "e7010c4278ee80e7",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 2: Create the Drawing Canvas\n",
    "\n",
    "We will create a `Canvas` class that allows users to draw stick figures.\n"
   ],
   "id": "8511707f4a4cbc10"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T08:37:31.797472Z",
     "start_time": "2024-07-25T08:37:31.791165Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Canvas(QWidget):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.setFixedSize(800, 500)\n",
    "        self.image = QPixmap(self.size())\n",
    "        self.image.fill(Qt.white)\n",
    "        self.drawing = False\n",
    "        self.last_point = QPoint()\n",
    "\n",
    "    def paintEvent(self, event):\n",
    "        canvas_painter = QPainter(self)\n",
    "        canvas_painter.drawPixmap(self.rect(), self.image, self.image.rect())\n",
    "\n",
    "    def mousePressEvent(self, event):\n",
    "        if event.button() == Qt.LeftButton:\n",
    "            self.drawing = True\n",
    "            self.last_point = event.pos()\n",
    "\n",
    "    def mouseMoveEvent(self, event):\n",
    "        if event.buttons() & Qt.LeftButton and self.drawing:\n",
    "            painter = QPainter(self.image)\n",
    "            painter.setPen(QPen(Qt.black, 4, Qt.SolidLine, Qt.RoundCap, Qt.RoundJoin))\n",
    "            painter.drawLine(self.last_point, event.pos())\n",
    "            self.last_point = event.pos()\n",
    "            self.update()\n",
    "\n",
    "    def mouseReleaseEvent(self, event):\n",
    "        if event.button() == Qt.LeftButton:\n",
    "            self.drawing = False\n",
    "\n",
    "    def save_image(self, path):\n",
    "        self.image.save(path)\n"
   ],
   "id": "84e7b15412f340b3",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 3: Create the Main Application Window\n",
    "\n",
    "We will create a `DrawingApp` class that includes the drawing canvas and a button to convert the drawing to a painting.\n"
   ],
   "id": "77373877eb627e93"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T08:37:31.805342Z",
     "start_time": "2024-07-25T08:37:31.798482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DrawingApp(QMainWindow):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.initUI()\n",
    "\n",
    "    def initUI(self):\n",
    "        self.setWindowTitle('Drawing App')\n",
    "        self.setGeometry(100, 100, 800, 800)\n",
    "\n",
    "        self.canvas = Canvas()\n",
    "        main_layout = QVBoxLayout()\n",
    "        main_layout.addWidget(self.canvas)\n",
    "\n",
    "        self.painting_label = QLabel(self)\n",
    "        main_layout.addWidget(self.painting_label)\n",
    "\n",
    "        btn = QPushButton('Convert to Painting', self)\n",
    "        btn.clicked.connect(self.convert_to_painting)\n",
    "        main_layout.addWidget(btn)\n",
    "\n",
    "        container = QWidget()\n",
    "        container.setLayout(main_layout)\n",
    "        self.setCentralWidget(container)\n",
    "\n",
    "    def convert_to_painting(self):\n",
    "        self.canvas.save_image('stick_figure.png')\n",
    "        image = preprocess_image('stick_figure.png')\n",
    "        painting = convert_to_painting(image)\n",
    "\n",
    "        # Convert painting to QImage\n",
    "        painting_qimage = self.pil_image_to_qimage(painting)\n",
    "        self.painting_label.setPixmap(QPixmap.fromImage(painting_qimage))\n",
    "\n",
    "    def pil_image_to_qimage(self, pil_image):\n",
    "        byte_data = BytesIO()\n",
    "        pil_image.save(byte_data, format=\"PNG\")\n",
    "        q_image = QImage()\n",
    "        q_image.loadFromData(byte_data.getvalue())\n",
    "        return q_image\n"
   ],
   "id": "2c8eea32ca30012",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 4: Preprocess the Image\n",
    "\n",
    "We need to preprocess the drawn image before sending it to the AI model.\n"
   ],
   "id": "178d32c9589116a2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T08:37:31.812465Z",
     "start_time": "2024-07-25T08:37:31.807342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    # Preprocess the image (resize, normalize, etc.) as required by the AI model\n",
    "    return image\n"
   ],
   "id": "53d2c5bc9a009b7",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 5: Convert the Image to a Painting\n",
    "\n",
    "We will use a pre-trained model from Hugging Face to convert the drawing to a painting.\n"
   ],
   "id": "33c02796bfda0945"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-25T08:37:31.822563Z",
     "start_time": "2024-07-25T08:37:31.814464Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def convert_to_painting(image):\n",
    "    # Load a pre-trained image-to-image translation model\n",
    "    model_id = \"stabilityai/stable-diffusion-2\"\n",
    "    pipe = StableDiffusionImg2ImgPipeline.from_pretrained(model_id, torch_dtype=torch.float16).to(\"cuda\")\n",
    "    prompt = \"A beautiful painting in the style of Van Gogh\"\n",
    "    result = pipe(prompt=prompt, init_image=image, strength=0.75, guidance_scale=7.5)\n",
    "    return result.images[0]\n"
   ],
   "id": "f198d87aabd6b135",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Step 6: Run the Application\n",
    "\n",
    "Finally, we will run the PyQt application within the Jupyter Notebook.\n"
   ],
   "id": "4ae2298601376a03"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-07-25T08:37:31.824574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_app():\n",
    "    app = QApplication.instance()\n",
    "    if app is None:\n",
    "        app = QApplication(sys.argv)\n",
    "    window = DrawingApp()\n",
    "    window.show()\n",
    "    app.exec_()\n",
    "\n",
    "\n",
    "# Run the application\n",
    "run_app()"
   ],
   "id": "3a8c19543691eaea",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model_index.json:   0%|          | 0.00/537 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "87c832616c2548d7a1456a812f04b34c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Fetching 13 files:   0%|          | 0/13 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c237fc4786c642a1b1392ffeaac55955"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "scheduler/scheduler_config.json:   0%|          | 0.00/345 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dbf7b240725440daac06fa2d8c8ef62b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "text_encoder/config.json:   0%|          | 0.00/633 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "13f17a7116e743278ac4d380bda8e01e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer/merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "83fa61140c14466b8f67d7f46ac1ce01"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(…)ature_extractor/preprocessor_config.json:   0%|          | 0.00/342 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7e9e9e8c3f3c4ec9a7566b52687b7ec3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer/tokenizer_config.json:   0%|          | 0.00/824 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1316d834c099461a83577775b6a6d5d4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer/vocab.json:   0%|          | 0.00/1.06M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "06c68381319d4bd4b137cf48e126d791"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.36G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4759013785df4c178ca24cccafc16bf1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "unet/config.json:   0%|          | 0.00/909 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ae7098bd13174e36af1fc3aa573b61a6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vae/config.json:   0%|          | 0.00/611 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "09134c8d402b486382fcfbfdf6f9ce68"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "diffusion_pytorch_model.safetensors:   0%|          | 0.00/3.46G [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "70e668165d7a4632aa3279b33c3c9e0a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "diffusion_pytorch_model.safetensors:   0%|          | 0.00/335M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2b38e3ff6c2945e3bce46ec2e4a5bc7c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer/special_tokens_map.json:   0%|          | 0.00/460 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "835d3322734e4976ad0489943d54bb7d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
